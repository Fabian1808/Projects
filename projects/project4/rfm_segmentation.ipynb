{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632d306d",
   "metadata": {},
   "source": [
    "# ðŸ“Š AnÃ¡lisis de SegmentaciÃ³n de Clientes con RFM y Machine Learning\n",
    "\n",
    "## ðŸŽ¯ Objetivo del Proyecto\n",
    "\n",
    "Este notebook demuestra cÃ³mo usar **SQL**, **Python** y **Machine Learning** para segmentar clientes de un e-commerce en grupos accionables utilizando la metodologÃ­a **RFM (Recencia, Frecuencia, Monetario)** y el algoritmo **K-Means**.\n",
    "\n",
    "### Â¿Por quÃ© es importante?\n",
    "- **Recencia (R)**: Â¿CuÃ¡n recientemente comprÃ³ el cliente?\n",
    "- **Frecuencia (F)**: Â¿CuÃ¡ntas veces ha comprado?\n",
    "- **Monetario (M)**: Â¿CuÃ¡nto dinero ha gastado?\n",
    "\n",
    "Combinando estas mÃ©tricas, identificaremos:\n",
    "- ðŸ† **Clientes Campeones**: Los mejores clientes, compradores frecuentes y recientes\n",
    "- âš ï¸ **Clientes en Riesgo**: Que no compran desde hace tiempo\n",
    "- ðŸ’ª **Clientes Leales**: Compradores consistentes\n",
    "- ðŸ†• **Clientes Nuevos**: Nuevas adquisiciones\n",
    "\n",
    "### ðŸ“š LibrerÃ­as Utilizadas\n",
    "- `sqlite3`: GestiÃ³n de base de datos SQL\n",
    "- `pandas`: ManipulaciÃ³n de datos\n",
    "- `numpy`: Operaciones numÃ©ricas\n",
    "- `sklearn`: Machine Learning (K-Means, StandardScaler)\n",
    "- `matplotlib` & `seaborn`: VisualizaciÃ³n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3340e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORTAR LIBRERÃAS NECESARIAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LibrerÃ­as de Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# VisualizaciÃ³n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar estilo de grÃ¡ficos\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ… Todas las librerÃ­as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809c550",
   "metadata": {},
   "source": [
    "## SecciÃ³n 1: Crear y Cargar Datos en Base de Datos SQLite\n",
    "\n",
    "En esta secciÃ³n, **cargamos datos CSV en una base de datos SQL**. Esto simula un entorno real donde los datos estÃ¡n en una BD en lugar de archivos CSV.\n",
    "\n",
    "### Â¿Por quÃ© es importante?\n",
    "- Aprendes a trabajar con **bases de datos reales** (como un verdadero analista)\n",
    "- Practicas **SQL** para consultar datos\n",
    "- Simulas un pipeline real: Datos â†’ BD â†’ AnÃ¡lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CARGAR DATOS Y LIMPIARLOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ðŸ“‚ Cargando datos del archivo CSV...\")\n",
    "\n",
    "# Cargar el CSV del proyecto anterior (usando ruta relativa)\n",
    "df = pd.read_csv('../project1/data.csv', encoding='latin1')\n",
    "\n",
    "print(f\"âœ… Datos cargados: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "print(f\"\\nColumnas disponibles:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5eba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. LIMPIAR Y PREPARAR DATOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nðŸ§¹ Limpiando datos...\")\n",
    "\n",
    "# Convertir InvoiceDate a datetime\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "# Eliminar filas con valores crÃ­ticos faltantes\n",
    "df = df.dropna(subset=['CustomerID', 'InvoiceNo', 'Country'])\n",
    "\n",
    "# Filtrar transacciones vÃ¡lidas (cantidad y precio positivos)\n",
    "df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
    "\n",
    "# Crear columna de precio total\n",
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "print(f\"âœ… Datos limpios: {df.shape[0]} filas vÃ¡lidas\")\n",
    "print(f\"ðŸ“Š PerÃ­odo de datos: {df['InvoiceDate'].min()} a {df['InvoiceDate'].max()}\")\n",
    "print(f\"ðŸ‘¥ Clientes Ãºnicos: {df['CustomerID'].nunique()}\")\n",
    "print(f\"ðŸ’° Ingresos totales: ${df['TotalPrice'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db869fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CREAR BASE DE DATOS SQLITE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nðŸ—„ï¸  Creando base de datos SQLite...\")\n",
    "\n",
    "# Crear conexiÃ³n a la base de datos (la crea si no existe)\n",
    "conn = sqlite3.connect('ecommerce.db')\n",
    "\n",
    "# Cargar el DataFrame en la tabla 'transacciones'\n",
    "df.to_sql('transacciones', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"âœ… Base de datos 'ecommerce.db' creada exitosamente\")\n",
    "print(\"âœ… Tabla 'transacciones' cargada con datos\")\n",
    "\n",
    "# Verificar que la tabla se creÃ³ correctamente\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT COUNT(*) FROM transacciones\")\n",
    "row_count = cursor.fetchone()[0]\n",
    "print(f\"ðŸ“Š Total de registros en BD: {row_count}\")\n",
    "\n",
    "cursor.execute(\"SELECT COUNT(DISTINCT CustomerID) FROM transacciones\")\n",
    "customer_count = cursor.fetchone()[0]\n",
    "print(f\"ðŸ‘¥ Total de clientes Ãºnicos en BD: {customer_count}\")\n",
    "\n",
    "conn.close()\n",
    "print(\"\\nâœ… ConexiÃ³n cerrada. Base de datos lista para consultas SQL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4815c2",
   "metadata": {},
   "source": [
    "## SecciÃ³n 2: Calcular MÃ©tricas RFM usando SQL\n",
    "\n",
    "Ahora conectaremos a nuestra base de datos y usaremos **SQL puro** para calcular:\n",
    "- **Recencia**: DÃ­as desde la Ãºltima compra\n",
    "- **Frecuencia**: Cantidad de transacciones\n",
    "- **Monetario**: Valor total gastado\n",
    "\n",
    "Esta es la parte clave: **escribimos SQL desde Python**. AsÃ­ trabajan los analistas reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. CONSULTAR BASE DE DATOS CON SQL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nðŸ” Consultando base de datos con SQL...\")\n",
    "\n",
    "# Conectar a la base de datos\n",
    "conn = sqlite3.connect('ecommerce.db')\n",
    "\n",
    "# CONSULTA SQL 1: Obtener mÃ©tricas RFM base\n",
    "# Esto es SQL puro, ejecutado directamente en la base de datos\n",
    "sql_rfm = \"\"\"\n",
    "SELECT\n",
    "    CustomerID,\n",
    "    MAX(InvoiceDate) AS UltimaFechaCompra,\n",
    "    COUNT(DISTINCT InvoiceNo) AS Frecuencia,\n",
    "    SUM(TotalPrice) AS Monetario\n",
    "FROM \n",
    "    transacciones\n",
    "GROUP BY \n",
    "    CustomerID\n",
    "ORDER BY \n",
    "    Monetario DESC\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar la consulta usando pandas (pandas se conecta a SQLite)\n",
    "df_rfm_base = pd.read_sql_query(sql_rfm, conn)\n",
    "\n",
    "print(f\"âœ… Consulta SQL ejecutada correctamente\")\n",
    "print(f\"ðŸ“Š Resultados: {df_rfm_base.shape[0]} clientes con mÃ©tricas RFM\")\n",
    "print(f\"\\nPrimeros 10 clientes (ordenados por Monetario):\")\n",
    "print(df_rfm_base.head(10))\n",
    "\n",
    "# Cerrar conexiÃ³n\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2166df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. CALCULAR RECENCIA EN PANDAS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâ° Calculando Recencia (dÃ­as desde Ãºltima compra)...\")\n",
    "\n",
    "# Convertir UltimaFechaCompra a datetime\n",
    "df_rfm_base['UltimaFechaCompra'] = pd.to_datetime(df_rfm_base['UltimaFechaCompra'])\n",
    "\n",
    "# Definir \"hoy\" como un dÃ­a despuÃ©s de la Ãºltima compra en el dataset\n",
    "fecha_maxima = df_rfm_base['UltimaFechaCompra'].max()\n",
    "hoy = fecha_maxima + dt.timedelta(days=1)\n",
    "\n",
    "# Calcular recencia en dÃ­as\n",
    "df_rfm_base['Recencia'] = (hoy - df_rfm_base['UltimaFechaCompra']).dt.days\n",
    "\n",
    "print(f\"ðŸ“… Fecha mÃ¡xima en datos: {fecha_maxima.date()}\")\n",
    "print(f\"ðŸ“… Fecha 'hoy' usada: {hoy.date()}\")\n",
    "print(f\"â³ Recencia mÃ­nima: {df_rfm_base['Recencia'].min()} dÃ­as\")\n",
    "print(f\"â³ Recencia mÃ¡xima: {df_rfm_base['Recencia'].max()} dÃ­as\")\n",
    "print(f\"â³ Recencia promedio: {df_rfm_base['Recencia'].mean():.0f} dÃ­as\")\n",
    "\n",
    "# Crear DataFrame final con RFM\n",
    "df_rfm = df_rfm_base[['CustomerID', 'Recencia', 'Frecuencia', 'Monetario']].copy()\n",
    "\n",
    "print(f\"\\nâœ… DataFrame RFM completado:\")\n",
    "print(df_rfm.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebfe472",
   "metadata": {},
   "source": [
    "## SecciÃ³n 3: Preprocesar Datos para Machine Learning\n",
    "\n",
    "El algoritmo K-Means es sensible a la escala de los datos:\n",
    "- Recencia: 0-200 dÃ­as\n",
    "- Frecuencia: 0-200 compras\n",
    "- Monetario: 0-100,000 USD\n",
    "\n",
    "Si usamos estos valores directamente, Monetario domina el algoritmo.\n",
    "\n",
    "**SoluciÃ³n**: \n",
    "1. Aplicar transformaciÃ³n logarÃ­tmica (log) para normalizar distribuciones sesgadas\n",
    "2. Usar StandardScaler para estandarizar todas las caracterÃ­sticas a la misma escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. PREPROCESAR DATOS PARA MACHINE LEARNING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nðŸ”§ Preprocesando datos para K-Means...\")\n",
    "\n",
    "# Paso 1: Aplicar transformaciÃ³n logarÃ­tmica\n",
    "# Esto ayuda a normalizar distribuciones sesgadas\n",
    "df_rfm_log = df_rfm[['Recencia', 'Frecuencia', 'Monetario']].copy()\n",
    "df_rfm_log = df_rfm_log.apply(lambda x: np.log1p(x), axis=1)  # log1p = log(1+x)\n",
    "\n",
    "print(\"âœ… TransformaciÃ³n logarÃ­tmica aplicada\")\n",
    "print(f\"\\nEstadÃ­sticas despuÃ©s de log transform:\")\n",
    "print(df_rfm_log.describe())\n",
    "\n",
    "# Paso 2: Estandarizar los datos (StandardScaler)\n",
    "# Esto pone todos los datos en la misma escala (media=0, desv.est=1)\n",
    "scaler = StandardScaler()\n",
    "rfm_scaled = scaler.fit_transform(df_rfm_log)\n",
    "\n",
    "print(f\"\\nâœ… StandardScaler aplicado\")\n",
    "print(f\"Forma de datos escalados: {rfm_scaled.shape}\")\n",
    "print(f\"Media de datos escalados: {rfm_scaled.mean(axis=0)}\")\n",
    "print(f\"Desv. estÃ¡ndar escalados: {rfm_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fbd88a",
   "metadata": {},
   "source": [
    "## SecciÃ³n 4: Aplicar K-Means Clustering\n",
    "\n",
    "K-Means es un algoritmo que:\n",
    "1. Divide los datos en **k clusters** (grupos)\n",
    "2. Cada cluster tiene un **centroide** (punto central)\n",
    "3. Cada cliente es asignado al cluster mÃ¡s cercano\n",
    "\n",
    "Para este proyecto, usaremos **4 clusters** porque identificamos 4 tipos de clientes:\n",
    "- Campeones\n",
    "- En Riesgo\n",
    "- Leales\n",
    "- Nuevos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0714b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. ENTRENAR MODELO K-MEANS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nðŸ¤– Entrenando modelo K-Means...\")\n",
    "\n",
    "# Crear y entrenar el modelo K-Means con 4 clusters\n",
    "# init='k-means++': inicializaciÃ³n inteligente de centroides\n",
    "# random_state=42: reproducibilidad\n",
    "# n_init=10: probar 10 inicializaciones diferentes\n",
    "kmeans = KMeans(\n",
    "    n_clusters=4,\n",
    "    init='k-means++',\n",
    "    random_state=42,\n",
    "    n_init=10,\n",
    "    max_iter=300\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "kmeans.fit(rfm_scaled)\n",
    "\n",
    "print(\"âœ… Modelo K-Means entrenado\")\n",
    "print(f\"ðŸ“Š Inercia (suma de distancias intra-cluster): {kmeans.inertia_:.2f}\")\n",
    "\n",
    "# Calcular Silhouette Score (mÃ©trica de calidad del clustering)\n",
    "# Rango: -1 a 1, mientras mÃ¡s cerca a 1, mejor\n",
    "silhouette_avg = silhouette_score(rfm_scaled, kmeans.labels_)\n",
    "print(f\"ðŸŽ¯ Silhouette Score: {silhouette_avg:.3f}\")\n",
    "\n",
    "# Asignar etiquetas de cluster a los clientes\n",
    "df_rfm['Segmento'] = kmeans.labels_\n",
    "\n",
    "print(f\"\\nâœ… Clusters asignados a todos los clientes\")\n",
    "print(f\"ðŸ“Š DistribuciÃ³n de clientes por cluster:\")\n",
    "print(df_rfm['Segmento'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267bdc11",
   "metadata": {},
   "source": [
    "## SecciÃ³n 5: Analizar e Interpretar Segmentos\n",
    "\n",
    "Ahora interpretaremos cada cluster basÃ¡ndonos en sus caracterÃ­sticas RFM:\n",
    "- **Recencia BAJA + Frecuencia ALTA + Monetario ALTO** â†’ Clientes Campeones ðŸ†\n",
    "- **Recencia ALTA + Frecuencia BAJA + Monetario BAJO** â†’ Clientes en Riesgo âš ï¸\n",
    "- **Recencia MEDIA + Frecuencia MEDIA + Monetario MEDIO** â†’ Clientes Leales ðŸ’ª\n",
    "- **Recencia BAJA + Frecuencia BAJA + Monetario BAJO** â†’ Clientes Nuevos ðŸ†•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. ANALIZAR CARACTERÃSTICAS DE CADA SEGMENTO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nðŸ“Š Analizando caracterÃ­sticas de cada segmento...\")\n",
    "\n",
    "# Calcular estadÃ­sticas por segmento\n",
    "segmentos_resumen = df_rfm.groupby('Segmento').agg({\n",
    "    'Recencia': ['mean', 'min', 'max'],\n",
    "    'Frecuencia': ['mean', 'min', 'max'],\n",
    "    'Monetario': ['mean', 'min', 'max'],\n",
    "    'CustomerID': 'count'\n",
    "}).round(2)\n",
    "\n",
    "# Aplanar los nombres de columnas para mejor legibilidad\n",
    "segmentos_resumen.columns = ['_'.join(col).strip() for col in segmentos_resumen.columns.values]\n",
    "segmentos_resumen = segmentos_resumen.rename(columns={'CustomerID_count': 'Total_Clientes'})\n",
    "\n",
    "print(\"\\nâœ… Resumen de segmentos:\")\n",
    "print(segmentos_resumen)\n",
    "\n",
    "# Crear un DataFrame mÃ¡s limpio para anÃ¡lisis\n",
    "segmentos_clean = df_rfm.groupby('Segmento').agg({\n",
    "    'Recencia': 'mean',\n",
    "    'Frecuencia': 'mean',\n",
    "    'Monetario': 'mean',\n",
    "    'CustomerID': 'count'\n",
    "}).round(2)\n",
    "segmentos_clean.columns = ['Recencia_Media', 'Frecuencia_Media', 'Monetario_Media', 'Total_Clientes']\n",
    "segmentos_clean['% del Total'] = (segmentos_clean['Total_Clientes'] / segmentos_clean['Total_Clientes'].sum() * 100).round(1)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Resumen Simplificado:\")\n",
    "print(segmentos_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd27da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. ASIGNAR NOMBRES A LOS SEGMENTOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nðŸ·ï¸  Interpretando segmentos basado en caracterÃ­sticas RFM...\")\n",
    "\n",
    "# BasÃ¡ndose en el anÃ¡lisis anterior, crear mapeo de clusters a nombres\n",
    "# Â¡IMPORTANTE!: Este mapeo debe ajustarse segÃºn los datos reales\n",
    "# Para este ejemplo, usamos la lÃ³gica RFM estÃ¡ndar\n",
    "\n",
    "def asignar_nombre_segmento(row):\n",
    "    \"\"\"\n",
    "    Asigna un nombre significativo a cada segmento basado en sus caracterÃ­sticas RFM\n",
    "    \"\"\"\n",
    "    recencia = row['Recencia_Media']\n",
    "    frecuencia = row['Frecuencia_Media']\n",
    "    monetario = row['Monetario_Media']\n",
    "    \n",
    "    # Calcular percentiles para comparaciÃ³n\n",
    "    recencia_percentil = recencia / df_rfm['Recencia'].max()\n",
    "    frecuencia_percentil = frecuencia / df_rfm['Frecuencia'].max()\n",
    "    monetario_percentil = monetario / df_rfm['Monetario'].max()\n",
    "    \n",
    "    # LÃ³gica de clasificaciÃ³n\n",
    "    if frecuencia_percentil >= 0.6 and monetario_percentil >= 0.6 and recencia_percentil <= 0.4:\n",
    "        return 'Campeones ðŸ†'\n",
    "    elif recencia_percentil >= 0.6 and frecuencia_percentil <= 0.4 and monetario_percentil <= 0.4:\n",
    "        return 'En Riesgo âš ï¸'\n",
    "    elif frecuencia_percentil >= 0.5 and monetario_percentil >= 0.5:\n",
    "        return 'Leales ðŸ’ª'\n",
    "    elif recencia_percentil <= 0.3 and frecuencia_percentil <= 0.4:\n",
    "        return 'Nuevos ðŸ†•'\n",
    "    else:\n",
    "        return 'Otros'\n",
    "\n",
    "# Aplicar la funciÃ³n para asignar nombres\n",
    "segmentos_clean['Nombre'] = segmentos_clean.apply(asignar_nombre_segmento, axis=1)\n",
    "\n",
    "# Agregar el nombre al DataFrame principal\n",
    "mapa_nombres = dict(zip(segmentos_clean.index, segmentos_clean['Nombre']))\n",
    "df_rfm['NombreSegmento'] = df_rfm['Segmento'].map(mapa_nombres)\n",
    "\n",
    "print(\"âœ… Nombres asignados a segmentos\")\n",
    "print(\"\\nðŸ“Œ Mapeo de Segmentos:\")\n",
    "for seg, nombre in mapa_nombres.items():\n",
    "    count = (df_rfm['Segmento'] == seg).sum()\n",
    "    pct = (count / len(df_rfm) * 100)\n",
    "    print(f\"   Cluster {seg}: {nombre} - {count} clientes ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3984172",
   "metadata": {},
   "source": [
    "## SecciÃ³n 6: Visualizar Resultados de SegmentaciÃ³n\n",
    "\n",
    "Ahora crearemos grÃ¡ficos para visualizar los segmentos y entender mejor las caracterÃ­sticas de cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. VISUALIZACIONES DE SEGMENTOS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nðŸ“Š Creando visualizaciones...\")\n",
    "\n",
    "# Crear figura con mÃºltiples subgrÃ¡ficos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('AnÃ¡lisis de SegmentaciÃ³n de Clientes RFM', fontsize=16, fontweight='bold')\n",
    "\n",
    "# GrÃ¡fico 1: DistribuciÃ³n de clientes por segmento (Pie Chart)\n",
    "ax1 = axes[0, 0]\n",
    "colores = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "segmento_counts = df_rfm['NombreSegmento'].value_counts()\n",
    "ax1.pie(segmento_counts.values, labels=segmento_counts.index, autopct='%1.1f%%', colors=colores, startangle=90)\n",
    "ax1.set_title('DistribuciÃ³n de Clientes por Segmento', fontweight='bold')\n",
    "\n",
    "# GrÃ¡fico 2: Recencia vs Monetario (Scatter)\n",
    "ax2 = axes[0, 1]\n",
    "scatter = ax2.scatter(df_rfm['Recencia'], df_rfm['Monetario'], \n",
    "                     c=df_rfm['Segmento'], cmap='viridis', alpha=0.6, s=50)\n",
    "ax2.set_xlabel('Recencia (dÃ­as)', fontweight='bold')\n",
    "ax2.set_ylabel('Monetario (USD)', fontweight='bold')\n",
    "ax2.set_title('Recencia vs Monetario por Segmento', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax2, label='Segmento')\n",
    "\n",
    "# GrÃ¡fico 3: MÃ©trica promedio por segmento (Bar Chart)\n",
    "ax3 = axes[1, 0]\n",
    "segmentos_metricas = df_rfm.groupby('NombreSegmento')[['Recencia', 'Frecuencia', 'Monetario']].mean()\n",
    "segmentos_metricas.plot(kind='bar', ax=ax3, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "ax3.set_title('MÃ©tricas Promedio por Segmento', fontweight='bold')\n",
    "ax3.set_ylabel('Valor Promedio', fontweight='bold')\n",
    "ax3.set_xlabel('Segmento', fontweight='bold')\n",
    "ax3.legend(title='MÃ©trica', loc='best')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# GrÃ¡fico 4: Frecuencia vs Monetario\n",
    "ax4 = axes[1, 1]\n",
    "for segmento in df_rfm['Segmento'].unique():\n",
    "    datos = df_rfm[df_rfm['Segmento'] == segmento]\n",
    "    ax4.scatter(datos['Frecuencia'], datos['Monetario'], \n",
    "               label=mapa_nombres[segmento], alpha=0.6, s=50)\n",
    "ax4.set_xlabel('Frecuencia (# compras)', fontweight='bold')\n",
    "ax4.set_ylabel('Monetario (USD)', fontweight='bold')\n",
    "ax4.set_title('Frecuencia vs Monetario', fontweight='bold')\n",
    "ax4.legend(loc='best')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Visualizaciones completadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe0c847",
   "metadata": {},
   "source": [
    "## SecciÃ³n 7: Recomendaciones de Negocio\n",
    "\n",
    "Basado en el anÃ¡lisis RFM, aquÃ­ estÃ¡n las estrategias accionables para cada segmento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc069d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. GENERAR RECOMENDACIONES DE NEGOCIO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ¯ RECOMENDACIONES DE NEGOCIO POR SEGMENTO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "recomendaciones = {\n",
    "    'Campeones ðŸ†': {\n",
    "        'descripcion': 'Clientes de alto valor que compran frecuentemente y recientemente',\n",
    "        'acciones': [\n",
    "            'âœ… Programa VIP exclusivo con descuentos y beneficios especiales',\n",
    "            'âœ… Acceso anticipado a nuevos productos',\n",
    "            'âœ… Soporte premium y atenciÃ³n personalizada',\n",
    "            'âœ… Recompensas por lealtad (puntos, regalos)',\n",
    "            'âœ… Invitaciones a eventos especiales'\n",
    "        ],\n",
    "        'objetivo': 'Retener a los mejores clientes y maximizar su lifetime value'\n",
    "    },\n",
    "    'En Riesgo âš ï¸': {\n",
    "        'descripcion': 'Clientes que no compran hace tiempo, bajo valor, baja frecuencia',\n",
    "        'acciones': [\n",
    "            'âœ… CampaÃ±a de \"Te extraÃ±amos\" con descuento atractivo',\n",
    "            'âœ… Email marketing personalizado con ofertas relevantes',\n",
    "            'âœ… Encuesta de satisfacciÃ³n para entender por quÃ© dejaron de comprar',\n",
    "            'âœ… Ofertas de reactivaciÃ³n con urgencia (tiempo limitado)',\n",
    "            'âœ… Recordatorios periÃ³dicos sin ser invasivo'\n",
    "        ],\n",
    "        'objetivo': 'Reactivar clientes y evitar que se conviertan en inactivos'\n",
    "    },\n",
    "    'Leales ðŸ’ª': {\n",
    "        'descripcion': 'Clientes con compras consistentes, valor moderado',\n",
    "        'acciones': [\n",
    "            'âœ… Programa de lealtad con puntos acumulables',\n",
    "            'âœ… Compras cruzadas recomendadas (cross-sell)',\n",
    "            'âœ… Venta adicional de productos premium (upsell)',\n",
    "            'âœ… Contenido exclusivo y educativo',\n",
    "            'âœ… Comunidad de clientes con beneficios'\n",
    "        ],\n",
    "        'objetivo': 'Incrementar valor de compra y convertirlos en Campeones'\n",
    "    },\n",
    "    'Nuevos ðŸ†•': {\n",
    "        'descripcion': 'Clientes recientes, valor bajo, baja frecuencia',\n",
    "        'acciones': [\n",
    "            'âœ… Bienvenida personalizada con guÃ­a de productos',\n",
    "            'âœ… Descuento o cupÃ³n para segunda compra',\n",
    "            'âœ… Tutorial de uso de plataforma (si aplica)',\n",
    "            'âœ… Encuesta de experiencia para mejorar',\n",
    "            'âœ… Emails educativos sobre productos populares'\n",
    "        ],\n",
    "        'objetivo': 'Convertir en clientes recurrentes y aumentar frecuencia'\n",
    "    }\n",
    "}\n",
    "\n",
    "for segmento, info in recomendaciones.items():\n",
    "    print(f\"\\n{segmento}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"ðŸ“Œ DescripciÃ³n: {info['descripcion']}\")\n",
    "    print(f\"ðŸ“Œ Objetivo: {info['objetivo']}\")\n",
    "    print(f\"\\nðŸ“‹ Acciones recomendadas:\")\n",
    "    for accion in info['acciones']:\n",
    "        print(f\"   {accion}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe5049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. EXPORTAR RESULTADOS Y CREAR ARCHIVOS FINALES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nðŸ’¾ Exportando resultados...\")\n",
    "\n",
    "# Exportar clientes segmentados a CSV\n",
    "df_rfm.to_csv('clientes_segmentados.csv', index=False)\n",
    "print(\"âœ… Archivo 'clientes_segmentados.csv' generado\")\n",
    "\n",
    "# Exportar resumen de segmentos\n",
    "segmentos_clean.to_csv('resumen_segmentos.csv')\n",
    "print(\"âœ… Archivo 'resumen_segmentos.csv' generado\")\n",
    "\n",
    "# Exportar modelo KMeans (opcional)\n",
    "import pickle\n",
    "with open('kmeans_model.pkl', 'wb') as f:\n",
    "    pickle.dump({'model': kmeans, 'scaler': scaler}, f)\n",
    "print(\"âœ… Modelo K-Means guardado en 'kmeans_model.pkl'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š RESUMEN FINAL DEL PROYECTO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nâœ… Base de datos SQLite creada: 'ecommerce.db'\")\n",
    "print(f\"âœ… Clientes analizados: {len(df_rfm):,}\")\n",
    "print(f\"âœ… Segmentos identificados: 4\")\n",
    "print(f\"âœ… Silhouette Score: {silhouette_avg:.3f}\")\n",
    "print(f\"\\nðŸ“ Archivos generados:\")\n",
    "print(f\"   â€¢ clientes_segmentados.csv\")\n",
    "print(f\"   â€¢ resumen_segmentos.csv\")\n",
    "print(f\"   â€¢ kmeans_model.pkl\")\n",
    "print(f\"   â€¢ ecommerce.db\")\n",
    "print(f\"\\nðŸ“Š DistribuciÃ³n de segmentos:\")\n",
    "for nombre, count in df_rfm['NombreSegmento'].value_counts().items():\n",
    "    pct = (count / len(df_rfm) * 100)\n",
    "    print(f\"   {nombre}: {count:,} clientes ({pct:.1f}%)\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ‰ Â¡Proyecto RFM completado exitosamente!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
